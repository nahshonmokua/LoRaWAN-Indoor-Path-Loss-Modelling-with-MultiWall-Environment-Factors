{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0731ebb-947f-42f6-b67f-746cac323711",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 40px; font-weight: bold; color: blue;  text-align: center;\">\n",
    "  LoRaWAN Path Loss Measurements in an Indoor Setting: DATA QUERYING from InfluxdB\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53f08d57-f8ec-4201-84e0-cb2920960d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries/Packages Used:\n",
    "import os                            # For accessing environment variables\n",
    "from dotenv import load_dotenv       # To load environment variables from the .env file\n",
    "import pandas as pd                  # For data manipulation and handling timezones\n",
    "from influxdb import InfluxDBClient  # To interact with InfluxDB (a time-series database)\n",
    "import time                          # For sleep function between batches\n",
    "import pathlib                       # For checking if file exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a3bf8e6-1e2a-44c9-87ea-6a0472a3e896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the variables\n",
    "host = os.getenv('INFLUXDB_HOST')\n",
    "port = int(os.getenv('INFLUXDB_PORT'))  # port is an integer\n",
    "database = os.getenv('INFLUXDB_DATABASE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0363bdd-9d2a-458a-9af2-3640aff64b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(start_time, end_time):\n",
    "    \"\"\"\n",
    "    Fetch sensor data from InfluxDB between specified start and end times.\n",
    "\n",
    "    Converts input times from Europe/Berlin to UTC for querying, then back to Europe/Berlin for use.\n",
    "    Returns data as a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    # Initialize the InfluxDB client\n",
    "    client = InfluxDBClient(host=host, port=port)\n",
    "    client.switch_database(database)\n",
    "\n",
    "    # Convert input times (Europe/Berlin) to UTC for the query\n",
    "    start_time_utc = pd.to_datetime(start_time).tz_localize('Europe/Berlin').tz_convert('UTC').strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "    end_time_utc = pd.to_datetime(end_time).tz_localize('Europe/Berlin').tz_convert('UTC').strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "    # Querying with the provided start_time and end_time in UTC\n",
    "    # '>' for start_time to exclude the last fetched timestamp\n",
    "    query = f\"SELECT * FROM sensor_data WHERE time > '{start_time_utc}' AND time <= '{end_time_utc}'\"\n",
    "\n",
    "    result = client.query(query)\n",
    "    df = pd.DataFrame(list(result.get_points()))\n",
    "\n",
    "    if not df.empty:\n",
    "        # Convert 'time' column to datetime with utc=True\n",
    "        df['time'] = pd.to_datetime(df['time'], utc=True, format='ISO8601').dt.tz_convert('Europe/Berlin')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4f22f09-bbbb-4e90-973b-41a9d8d1d56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data_in_batches(start_time, end_time):\n",
    "    \"\"\"\n",
    "    Fetch sensor data in batches of 10 days with a 2-minute  break between each batch.\n",
    "    \"\"\"\n",
    "    # Convert start_time to a datetime object\n",
    "    start_time = pd.to_datetime(start_time)\n",
    "\n",
    "    # Check if start_time is timezone-naive; if so, localize it\n",
    "    if start_time.tzinfo is None:\n",
    "        start_time = start_time.tz_localize('Europe/Berlin')\n",
    "    else:\n",
    "        start_time = start_time.tz_convert('Europe/Berlin')\n",
    "\n",
    "    # Check if end_time is timezone-naive; if so, localize it\n",
    "    end_time = pd.to_datetime(end_time)\n",
    "    if end_time.tzinfo is None:\n",
    "        end_time = end_time.tz_localize('Europe/Berlin')\n",
    "    else:\n",
    "        end_time = end_time.tz_convert('Europe/Berlin')\n",
    "\n",
    "    # Initialize a list to store DataFrames\n",
    "    df_list = []\n",
    "\n",
    "    current_start = start_time\n",
    "    delta = pd.Timedelta(days=10)\n",
    "\n",
    "    while current_start < end_time:\n",
    "        current_end = min(current_start + delta, end_time)\n",
    "\n",
    "        print(f\"Fetching data from {current_start} to {current_end}\")\n",
    "\n",
    "        # Fetch data for the current interval\n",
    "        df = fetch_data(current_start.strftime('%Y-%m-%d %H:%M:%S'), current_end.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "        if not df.empty:\n",
    "            df_list.append(df)\n",
    "\n",
    "        # Sleep for 2 minutes between queries\n",
    "        if current_end < end_time:\n",
    "            print(\"Sleeping for 2 minutes...\")\n",
    "            time.sleep(120)\n",
    "\n",
    "        # Move to the next interval\n",
    "        current_start = current_end\n",
    "\n",
    "    # Combine all DataFrames\n",
    "    if df_list:\n",
    "        batch_combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    else:\n",
    "        batch_combined_df = pd.DataFrame()\n",
    "\n",
    "    return batch_combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "093ef4cc-19f3-4546-aeee-458d186b8db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming data fetching from 2025-01-17 11:10:22.711806+01:00.\n",
      "Fetching data from 2025-01-17 11:10:22.711806+01:00 to 2025-01-25 23:18:23.019968+01:00\n",
      "Data fetching completed and saved to '../all_data_files/unsorted_combined_measurements_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# File path for the combined data CSV\n",
    "csv_file_path = '../all_data_files/unsorted_combined_measurements_data.csv'\n",
    "\n",
    "# Starting campaign time\n",
    "initial_start_time = '2024-09-26 13:00:00'  # Berlin time\n",
    "\n",
    "# Check if the CSV file exists\n",
    "file_exists = pathlib.Path(csv_file_path).exists()\n",
    "\n",
    "if file_exists:\n",
    "    # Read existing data\n",
    "    combined_df = pd.read_csv(csv_file_path, parse_dates=['time'], low_memory=False)\n",
    "    if not combined_df.empty:\n",
    "        # Get the last timestamp\n",
    "        last_timestamp = combined_df['time'].max()\n",
    "        # Start from the last timestamp\n",
    "        start_time = last_timestamp\n",
    "        print(f\"Resuming data fetching from {start_time}.\")\n",
    "    else:\n",
    "        # If CSV is empty, start from the initial start time\n",
    "        start_time = initial_start_time\n",
    "        print(f\"The existing CSV file is empty. Starting data fetching from {start_time}.\")\n",
    "else:\n",
    "    # Initialize an empty DataFrame for combined_df\n",
    "    combined_df = pd.DataFrame()\n",
    "    # Start from the initial start time\n",
    "    start_time = initial_start_time\n",
    "    print(f\"No existing CSV file found. Starting data fetching from {start_time}.\")\n",
    "\n",
    "# End time is the current time\n",
    "end_time = pd.Timestamp.now(tz='Europe/Berlin')  # Current time in Berlin timezone\n",
    "\n",
    "# Fetch data in batches\n",
    "new_data_df = fetch_data_in_batches(start_time, end_time)\n",
    "\n",
    "# Combine with existing data\n",
    "if not new_data_df.empty:\n",
    "    # Append new data to combined_df\n",
    "    combined_df = pd.concat([combined_df, new_data_df], ignore_index=True)\n",
    "    # Drop duplicates based on 'time' column\n",
    "    combined_df.drop_duplicates(subset='time', inplace=True)\n",
    "    # Save the combined DataFrame to the CSV file\n",
    "    combined_df.to_csv(csv_file_path, index=False)\n",
    "    print(f\"Data fetching completed and saved to '{csv_file_path}'.\")\n",
    "else:\n",
    "    print(\"No new data fetched.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_models_env)",
   "language": "python",
   "name": "ml_models_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
